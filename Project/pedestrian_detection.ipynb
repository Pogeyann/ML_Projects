{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEDESTRIAN DETECTION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image file reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[197, 213, 230],\n",
       "        [209, 228, 241],\n",
       "        [140, 163, 171],\n",
       "        ...,\n",
       "        [122, 142, 177],\n",
       "        [130, 156, 193],\n",
       "        [ 99, 126, 170]],\n",
       "\n",
       "       [[211, 234, 250],\n",
       "        [166, 189, 204],\n",
       "        [203, 231, 238],\n",
       "        ...,\n",
       "        [ 99, 118, 151],\n",
       "        [104, 127, 165],\n",
       "        [ 91, 119, 160]],\n",
       "\n",
       "       [[187, 220, 235],\n",
       "        [160, 194, 207],\n",
       "        [194, 227, 236],\n",
       "        ...,\n",
       "        [132, 150, 181],\n",
       "        [133, 155, 191],\n",
       "        [141, 166, 206]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[124, 131, 148],\n",
       "        [134, 142, 159],\n",
       "        [127, 134, 151],\n",
       "        ...,\n",
       "        [131, 138, 153],\n",
       "        [ 49,  55,  68],\n",
       "        [100, 102, 112]],\n",
       "\n",
       "       [[122, 127, 142],\n",
       "        [119, 126, 141],\n",
       "        [113, 118, 133],\n",
       "        ...,\n",
       "        [127, 136, 146],\n",
       "        [ 55,  62,  71],\n",
       "        [105, 108, 116]],\n",
       "\n",
       "       [[125, 130, 145],\n",
       "        [122, 127, 142],\n",
       "        [112, 117, 132],\n",
       "        ...,\n",
       "        [120, 129, 139],\n",
       "        [ 55,  63,  70],\n",
       "        [110, 113, 121]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = cv2.imread(\"/home/mush/Computer_vision/Project/WhatsApp Image 2023-01-17 at 18.05.13.jpeg\")\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',input)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier Training\n",
    "\n",
    "classifier=cv2.CascadeClassifier(\"/home/mush/Computer_vision/Project/haarcascade_fullbody.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pedestrian Detected:  4\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"/home/mush/Computer_vision/Project/WhatsApp Image 2023-01-17 at 18.05.13.jpeg\")\n",
    "\n",
    "def pedestrian_detection(frame):\n",
    "    gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    pedestrians=classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=1)\n",
    "    # to detect full body in the grayscale image\n",
    "    total_detections=0\n",
    "    # Detection of rectangle\n",
    "    for (x, y, w, h) in pedestrians:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, 'Person', (x+5, y-5), font, 0.5, (0, 255, 0), 1)\n",
    "        total_detections +=1\n",
    "\n",
    "    # Processing the image with detections\n",
    "    cv2.imshow(\"Pedestrian Detection\", frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Total Pedestrian Detected: \", total_detections)\n",
    "    return frame\n",
    "\n",
    "output = pedestrian_detection(image)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pedestrian Detection in a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = cv2.CascadeClassifier(\"/home/mush/Computer_vision/Project/haarcascade_fullbody.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video capture and reading[]\n",
    "\n",
    "# Video Writing ,pedestrian detection drawing rectangle around detection\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"/home/mush/Computer_vision/Project/WhatsApp Video 2023-01-17 at 13.07.42.mp4\")\n",
    "ret, frame=cap.read()\n",
    "frame_height, frame_width, _ = frame.shape\n",
    "# (height, width & no.of color channels) is then determined using attribute \n",
    "# and assigned to the variables\n",
    "# Defining the codec and creating a video writer object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter('output_video.avi', fourcc, 30,(frame_width, frame_height))\n",
    "#The video above writes the processed frames of the video to a newfile.\n",
    "# fps 30 \n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detecting pedestrians in the frame\n",
    "    pedestrians = classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "\n",
    "    # Plotting rectangles around the detections\n",
    "    for (x, y, w, h) in pedestrians:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, 'Pedestrian', (x, y - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    out.write(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[0;32m---> 16\u001b[0m     gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(frame, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[1;32m     18\u001b[0m     \u001b[39m# Detecting pedestrians in the frame\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     pedestrians \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mdetectMultiScale(gray, scaleFactor\u001b[39m=\u001b[39m\u001b[39m1.1\u001b[39m, minNeighbors\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, minSize\u001b[39m=\u001b[39m(\u001b[39m30\u001b[39m, \u001b[39m30\u001b[39m))\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Calculates pedestrian count\n",
    "\n",
    "cap = cv2.VideoCapture('/home/mush/Computer_vision/Project/WhatsApp Video 2023-01-17 at 13.07.42.mp4')\n",
    "ret, frame = cap.read()\n",
    "frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "# Define the codec and create a video writer object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter('output_video.avi', fourcc, 30, (frame_width, frame_height))\n",
    "\n",
    "# Initialize a counter for the total number of pedestrians detected\n",
    "pedestrian_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detecting pedestrians in the frame\n",
    "    pedestrians = classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Increment the pedestrian counter for each detection\n",
    "    pedestrian_count += len(pedestrians)\n",
    "    \n",
    "    # Plotting rectangles around the detections\n",
    "    for (x, y, w, h) in pedestrians:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, 'Pedestrian', (x, y - 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the total number of pedestrians detected on the video\n",
    "    cv2.putText(frame, f'Total Pedestrian detections: {pedestrian_count}',(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    out.write(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'cv2.VideoCapture' object has no attribute 'waitkey'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n\u001b[1;32m     22\u001b[0m cap\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m---> 23\u001b[0m cap\u001b[39m.\u001b[39;49mwaitkey(\u001b[39m5000\u001b[39m)\n\u001b[1;32m     24\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'cv2.VideoCapture' object has no attribute 'waitkey'"
     ]
    }
   ],
   "source": [
    "#For playing \n",
    "\n",
    "cap = cv2.VideoCapture(r\"/home/mush/Computer_vision/Project/WhatsApp Video 2023-01-17 at 13.07.42.mp4\")\n",
    "ret, frame = cap.read()\n",
    "frame_height, frame_width, _ = frame.shape\n",
    "pedestrian_count = 0\n",
    "while ret:\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Detecting pedestrians in the frame\n",
    "    pedestrians = classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    pedestrian_count += len(pedestrians)\n",
    "\n",
    "    # Plotting rectangles around the detections\n",
    "    for (x, y, w, h) in pedestrians:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, 'Pedestrian', (x, y - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the total number of pedestrians detected on the video\n",
    "    cv2.putText(frame, f'Total Pedestrian detections: {pedestrian_count}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "cap.waitkey(5000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
