{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LANE DETECTION\n",
    "--"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self driving cars use lane detection opencv features to detect lanes of the roads and they are not to drive outside of the line."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Capturing and decoding video file frame by frame\n",
    "* Conversion of the image to grayscale\n",
    "* Applying filters to reduce noice in video frames\n",
    "* Edge Detection using canny edge detection method\n",
    "* Finding the region of interest and working on that part\n",
    "* Detecting lanes using Hough line transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "videocapture()\n",
    "0-for front camera and 1 for the rear camera.\n",
    "\n",
    "read() function when applied on captured video either from video source or camera, returns retention value i.e bool value (True or False), and the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videolanes():\n",
    "    video = cv.VideoCapture('/home/mush/Computer_vision/project1/Lane detection/Lane.mp4')\n",
    "    while True: # video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        frame = lanesDetection(frame)\n",
    "        cv.imshow('Lanes Detection', frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "video = cv.VideoCapture('/home/mush/Computer_vision/project1/Lane detection/Lane.mp4')\n",
    "\n",
    "frames = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "   \n",
    "    if not ret:\n",
    "        break\n",
    "    frames.append(frame)\n",
    "\n",
    "#Get the shape of the video\n",
    "\n",
    "shapes = frames[0].shape\n",
    "print(shapes)\n",
    "\n",
    "#Release the video capture object\n",
    "video.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape() function returns height, width, and the dimension of the metrics of the colors of the image.\n",
    "\n",
    "Next, Vertices of the region of interest are marked. You will have to calculate the region of interest of your source image i.e Video frame if you are using another video as it will have lanes in a different position and this calculation will not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes two parameters:\n",
    "\n",
    "1. Canny Edge Detection image.\n",
    "2. The Region of Interest Vertices in form of Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv.imread('/home/mush/Computer_vision/project1/Lane detection/Lane.mp4')\n",
    "\n",
    "cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lanesDetection(img):\n",
    "\n",
    "    #print(img.shape)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "\n",
    "    region_of_interest_vertices = [(200, height), (width/2, height/1.37), (width-300, height)]\n",
    "\n",
    "# is defined as a list of coordinates specifying the vetices of a triangular region\n",
    "# of interest in the image. This region is defined as a triangle with its upper-left \n",
    "# corner at (200, height), its upper-right corner at (width/2, height/1.37), and its\n",
    "#  lower-right corner at (width-300, height).\n",
    "\n",
    "    gray_img = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "    edge = cv.Canny(gray_img, 50,100, apertureSize=3)\n",
    "    #Edge detection is applied using canny function\n",
    "    \n",
    "    cropped_image = region_of_interest(edge, np.array([region_of_interest_vertices], np.int32))\n",
    "\n",
    "\n",
    "    lines = cv.HoughLinesP(cropped_image, rho=2,theta=np.pi/180, threshold=50, lines=np.array([]), minLineLength=10, maxLineGap=30)\n",
    "\n",
    "    image_with_lines = draw_lines(img, lines)\n",
    "\n",
    "    #plt.imshow(image_with_lines)\n",
    "    #Plt.show()\n",
    "    return image_with_lines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HoughLinesP is a function in the OpenCV library for image processing that is used to detect straight lines in an image. It is an implementation of the Hough Transform algorithm, which is a technique for detecting geometric shapes in digital images. The function has the following parameters:\n",
    "\n",
    "image: The input image, which should be a grayscale image.\n",
    "rho: The resolution of the parameter r in pixels.\n",
    "theta: The resolution of the parameter theta in radians.\n",
    "threshold: The minimum number of intersections to \"vote\" for a line to be considered.\n",
    "minLineLength: The minimum length of a line in pixels.\n",
    "maxLineGap: The maximum gap between two points on the same line in pixels.\n",
    "The function returns an array of detected lines, represented by their start and end point coordinates (x1, y1, x2, y2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open cv region of Interest(ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img,vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    # channel_count = img.shape[2]\n",
    "    match_mask_color = (255)\n",
    "    cv.fillPoly(mask, vertices, match_mask_color)\n",
    "    masked_image = cv.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lines(img, lines):\n",
    "    img = np.copy(img)\n",
    "    blank_image = np.zeros((img.shape[0],img.shape[1], 3), np.uint8)\n",
    "\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv.line(blank_image, (x1,y1), (x2,y2), (0,255,0),2)\n",
    "\n",
    "    img = cv.addWeighted(img, 0.8, blank_image, 1, 0.0)\n",
    "    return img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
